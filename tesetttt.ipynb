{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T03:54:02.601984Z",
     "start_time": "2025-01-19T03:53:44.330510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install vaderSentiment\n",
    "!pip install vaderSentiment textblob\n",
    "\n"
   ],
   "id": "fc5322a2af9512c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (3.3.2)\r\n",
      "Requirement already satisfied: textblob in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (0.19.0)\r\n",
      "Requirement already satisfied: requests in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from vaderSentiment) (2.32.3)\r\n",
      "Requirement already satisfied: nltk>=3.9 in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from textblob) (3.9.1)\r\n",
      "Requirement already satisfied: click in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from nltk>=3.9->textblob) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from nltk>=3.9->textblob) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from nltk>=3.9->textblob) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from nltk>=3.9->textblob) (4.67.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages (from requests->vaderSentiment) (2024.8.30)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T03:54:43.514929Z",
     "start_time": "2025-01-19T03:54:02.627733Z"
    }
   },
   "cell_type": "code",
   "source": "!python -m spacy download en_core_web_sm\n",
   "id": "4900a1d562e8319b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\r\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/spacy/__init__.py\", line 6, in <module>\r\n",
      "    from .errors import setup_default_warnings\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/spacy/errors.py\", line 3, in <module>\r\n",
      "    from .compat import Literal\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/spacy/compat.py\", line 4, in <module>\r\n",
      "    from thinc.util import copy_array\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/thinc/__init__.py\", line 5, in <module>\r\n",
      "    from .config import registry\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/thinc/config.py\", line 5, in <module>\r\n",
      "    from .types import Decorator\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/thinc/types.py\", line 25, in <module>\r\n",
      "    from .compat import cupy, has_cupy\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/thinc/compat.py\", line 35, in <module>\r\n",
      "    import torch\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1382, in <module>\r\n",
      "    from .functional import *  # noqa: F403\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\r\n",
      "    import torch.nn.functional as F\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\r\n",
      "    from .modules import *  # noqa: F403\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\r\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\r\n",
      "  File \"/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\r\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n",
      "/Users/apple2015/Documents/MSc/SchoolStuff/NLP/Personal/Job Description Skill Analyzer/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\r\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n",
      "Collecting en-core-web-sm==3.8.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m7.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: en-core-web-sm\r\n",
      "Successfully installed en-core-web-sm-3.8.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-19T04:25:08.320959Z",
     "start_time": "2025-01-19T04:25:06.908941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def find_happy_words(sentence):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    doc = nlp(sentence)\n",
    "    happy_words = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Filter out function words using POS tagging\n",
    "        if token.pos_ in ['DET', 'ADP', 'CCONJ', 'PRON', 'PART', 'AUX', 'SCONJ']:\n",
    "            continue\n",
    "\n",
    "        sentiment = analyzer.polarity_scores(token.text)\n",
    "        # Check for positive sentiment using VADER\n",
    "        if sentiment['compound'] > 0.2:  # Adjust threshold to a more lenient value\n",
    "            happy_words.append(token.text)\n",
    "        else:\n",
    "            # Supplement analysis with TextBlob\n",
    "            blob = TextBlob(token.text)\n",
    "            if blob.sentiment.polarity > 0.2:  # Positive sentiment threshold for TextBlob\n",
    "                happy_words.append(token.text)\n",
    "\n",
    "    return happy_words\n",
    "\n",
    "sentence = \"Sunshine and smiles go hand in hand to create a beautiful day filled with endless possibilities!\"\n",
    "print(find_happy_words(sentence))\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T04:34:06.550624Z",
     "start_time": "2025-01-19T04:34:05.871391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit TF-IDF on the training data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(undersample_dataset['text'])\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a mapping of words to TF-IDF scores for each emotion\n",
    "emotion_words = {}\n",
    "for emotion in undersample_dataset['label'].unique():\n",
    "    subset = undersample_dataset[undersample_dataset['label'] == emotion]\n",
    "    scores = tfidf_vectorizer.fit_transform(subset['text']).mean(axis=0).A1\n",
    "    emotion_words[emotion] = {word: scores[idx] for idx, word in enumerate(feature_names)}\n",
    "\n",
    "# Analyze a sentence\n",
    "sentence = \"Sunshine and smiles go hand in hand to create a beautiful day filled with endless possibilities!\"\n",
    "words = sentence.split()\n",
    "emotion_scores = {emotion: sum(emotion_words[emotion].get(word.lower(), 0) for word in words) for emotion in emotion_words}\n",
    "print(emotion_scores)\n"
   ],
   "id": "cd00dde0532265bc",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'undersample_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Fit TF-IDF on the training data\u001B[39;00m\n\u001B[1;32m      4\u001B[0m tfidf_vectorizer \u001B[38;5;241m=\u001B[39m TfidfVectorizer(max_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m X_tfidf \u001B[38;5;241m=\u001B[39m tfidf_vectorizer\u001B[38;5;241m.\u001B[39mfit_transform(\u001B[43mundersample_dataset\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      6\u001B[0m feature_names \u001B[38;5;241m=\u001B[39m tfidf_vectorizer\u001B[38;5;241m.\u001B[39mget_feature_names_out()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Create a mapping of words to TF-IDF scores for each emotion\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'undersample_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e885f6f0f33fc982"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
