{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Emotion Analysis",
   "id": "acbc7d2403c10b3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import Libraries",
   "id": "affe3330009c94a2"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "# from tensorflow.keras import layers, models"
   ],
   "id": "da29198623cafa10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load and Explore Data",
   "id": "95518ec18d1eaba6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load the dataset from a file.\"\"\"\n",
    "    return pd.read_csv(file_path)"
   ],
   "id": "bb8f92b59e62f46f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def explore_data(df, text_column='text'):\n",
    "    \"\"\"\n",
    "    Perform an extensive exploration of the dataset to check data cleanliness.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    - text_column: Name of the column containing text data\n",
    "\n",
    "    Returns:\n",
    "    - Summary of findings\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Basic Information ---\")\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Missing Values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicate Rows: {df.duplicated().sum()}\")\n",
    "\n",
    "    print(\"\\n--- Class Distribution ---\")\n",
    "    if 'label' in df.columns:\n",
    "        print(df['label'].value_counts())\n",
    "    else:\n",
    "        print(\"No 'label' column found!\")\n",
    "\n",
    "    print(\"\\n--- Text Analysis ---\")\n",
    "    # Check for empty or blank text\n",
    "    empty_texts = df[text_column].isnull().sum() + df[text_column].str.strip().eq('').sum()\n",
    "    print(f\"Empty or Blank Texts: {empty_texts}\")\n",
    "\n",
    "    # Check for punctuation\n",
    "    punctuations = df[text_column].apply(lambda x: len(re.findall(r'[^\\w\\s]', str(x))))\n",
    "    print(f\"Average Punctuation Count per Entry: {punctuations.mean():.2f}\")\n",
    "\n",
    "    # Check for emojis\n",
    "    emojis = df[text_column].apply(lambda x: len(emoji.emoji_list(str(x))))\n",
    "    print(f\"Average Emoji Count per Entry: {emojis.mean():.2f}\")\n",
    "\n",
    "    # Check for stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_word_counts = df[text_column].apply(lambda x: len([word for word in str(x).split() if word.lower() in stop_words]))\n",
    "    print(f\"Average Stop Words per Entry: {stop_word_counts.mean():.2f}\")\n",
    "\n",
    "    # Check for special characters (non-alphanumeric)\n",
    "    special_chars = df[text_column].apply(lambda x: len(re.findall(r'[^\\w\\s]', str(x))))\n",
    "    print(f\"Average Special Characters per Entry: {special_chars.mean():.2f}\")\n",
    "\n",
    "    print(\"\\n--- Recommendations ---\")\n",
    "    recommendations = []\n",
    "    if empty_texts > 0:\n",
    "        recommendations.append(f\"Remove or handle {empty_texts} empty or blank entries.\")\n",
    "    if df.duplicated().sum() > 0:\n",
    "        recommendations.append(\"Remove duplicate rows.\")\n",
    "    if emojis.mean() > 0:\n",
    "        recommendations.append(\"Consider handling emojis (e.g., replace with words or remove).\")\n",
    "    if punctuations.mean() > 0:\n",
    "        recommendations.append(\"Remove or handle punctuation marks appropriately.\")\n",
    "    if special_chars.mean() > 0:\n",
    "        recommendations.append(\"Clean special characters from text.\")\n",
    "\n",
    "    if recommendations:\n",
    "        print(\"\\n\".join(recommendations))\n",
    "    else:\n",
    "        print(\"The dataset appears clean!\")"
   ],
   "id": "357f3cf7a7ccacd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Drop empty rows from our data\n",
    "def drop_empty_rows(df):\n",
    "    \"\"\"Drop rows with empty text values.\"\"\"\n",
    "    return df.dropna(subset=['text']).reset_index(drop=True)"
   ],
   "id": "e155f6e315113b26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Preprocess Text",
   "id": "339eedc44668e730"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:22.034174Z",
     "start_time": "2024-12-08T18:58:22.025693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_emojis(text):\n",
    "    \"\"\"Remove emojis from text.\"\"\"\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "def remove_punctuation_and_symbols(text):\n",
    "    \"\"\"Remove punctuation, numbers, and special characters.\"\"\"\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text.\"\"\"\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_punctuation_and_symbols(text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def apply_preprocessing(df):\n",
    "    \"\"\"Apply preprocessing to the text column.\"\"\"\n",
    "    df['text'] = df['text'].apply(preprocess_text)\n",
    "    return df\n"
   ],
   "id": "88bd508c16219733",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature Engineering",
   "id": "2371f0912fa9de6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:27.289929Z",
     "start_time": "2024-12-08T18:58:27.276910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_features(corpus):\n",
    "    \"\"\"Convert text into numerical representations.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return features, vectorizer"
   ],
   "id": "3ae90cd91878a822",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model Training",
   "id": "9ed49450c558445c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Logistic Regression",
   "id": "a8cdcfa189750968"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:31.467768Z",
     "start_time": "2024-12-08T18:58:31.460899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_logistic_regression(X, y):\n",
    "    \"\"\"Train and evaluate a Logistic Regression model.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- Logistic Regression Evaluation ---\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model"
   ],
   "id": "e63d7bfe4eacfe85",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Random Forest",
   "id": "8dfbb560f6a2a251"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:34.658590Z",
     "start_time": "2024-12-08T18:58:34.639346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_random_forest(X, y):\n",
    "    \"\"\"Train and evaluate a Random Forest Classifier.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- Random Forest Evaluation ---\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model"
   ],
   "id": "1d2a6f4e4cd8223e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Support Vector Machine",
   "id": "7153c9dd7aacc9bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:37.416652Z",
     "start_time": "2024-12-08T18:58:37.399382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_svm(X, y):\n",
    "    \"\"\"Train and evaluate a Support Vector Machine (SVM).\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = SVC(probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- SVM Evaluation ---\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model\n"
   ],
   "id": "280ea5462c80f349",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Evaluate Model",
   "id": "3164d5a10ba74dd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:39.222136Z",
     "start_time": "2024-12-08T18:58:39.199537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Evaluation Function\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the performance of a trained model.\"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))"
   ],
   "id": "52e290795d534f01",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Predict",
   "id": "f39275ac3d8f700a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T18:58:41.926293Z",
     "start_time": "2024-12-08T18:58:41.893766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_emotion(model, text, vectorizer):\n",
    "    \"\"\"Predict the emotion of a single input text.\"\"\"\n",
    "    processed_text = preprocess_text(text)\n",
    "    features = vectorizer.transform([processed_text])\n",
    "    return model.predict(features)\n"
   ],
   "id": "c8a1e03edcde6613",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:29:41.901209Z",
     "start_time": "2024-12-08T19:29:28.727042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = load_data('sampled_data.csv')\n",
    "explore_data(df, text_column='text')  # Adjust 'text' if your column name differs\n"
   ],
   "id": "41c5271ce0040574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Basic Information ---\n",
      "Dataset Shape: (100000, 2)\n",
      "Columns: ['text', 'label']\n",
      "Missing Values:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "Duplicate Rows: 0\n",
      "\n",
      "--- Class Distribution ---\n",
      "label\n",
      "0    20000\n",
      "1    20000\n",
      "2    20000\n",
      "3    20000\n",
      "4    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Text Analysis ---\n",
      "Empty or Blank Texts: 0\n",
      "Average Punctuation Count per Entry: 0.00\n",
      "Average Emoji Count per Entry: 0.00\n",
      "Average Stop Words per Entry: 9.99\n",
      "Average Special Characters per Entry: 0.00\n",
      "\n",
      "--- Recommendations ---\n",
      "The dataset appears clean!\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:39:30.767097Z",
     "start_time": "2024-12-08T19:29:57.704939Z"
    }
   },
   "cell_type": "code",
   "source": "df = apply_preprocessing(df)",
   "id": "d8e40409574a510c",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:40:51.080212Z",
     "start_time": "2024-12-08T19:40:43.447302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, vectorizer = create_features(df['text'])  # 'text' is the name of your text column\n",
    "y = df['label']  # Assuming the label column is named 'label'\n",
    "\n",
    "logistic_model = train_logistic_regression(X, y)"
   ],
   "id": "332940142b1a869c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      4018\n",
      "           1       0.94      0.92      0.93      4015\n",
      "           2       0.93      0.97      0.95      4002\n",
      "           3       0.94      0.94      0.94      3987\n",
      "           4       0.94      0.96      0.95      3978\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.94      0.94      0.94     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:46:41.986155Z",
     "start_time": "2024-12-08T19:46:41.882302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the label to emotion mapping\n",
    "label_to_emotion = {\n",
    "    0: 'sadness',\n",
    "    1: 'joy',\n",
    "    2: 'love',\n",
    "    3: 'anger',\n",
    "    4: 'fear'\n",
    "}\n",
    "\n",
    "\n",
    "# text_to_predict = \"I am so happy today!\"\n",
    "text_to_predict = \"it doesn't necessarily convey sadness or disappointment.\"\n",
    "\n",
    "# Use the trained Logistic Regression model\n",
    "predicted_emotion_logistic = predict_emotion(logistic_model, text_to_predict, vectorizer)\n",
    "print(f\"Predicted emotion (Logistic Regression): {predicted_emotion_logistic}\")\n"
   ],
   "id": "3847ac9d9651a15a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotion (Logistic Regression): [0]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:48:12.455710Z",
     "start_time": "2024-12-08T19:48:11.860619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"\\n--- Logistic Regression Evaluation ---\")\n",
    "evaluate_model(logistic_model, X, y)\n",
    "\n"
   ],
   "id": "1d84b33ec3d86e1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     20000\n",
      "           1       0.96      0.93      0.95     20000\n",
      "           2       0.94      0.98      0.96     20000\n",
      "           3       0.96      0.96      0.96     20000\n",
      "           4       0.95      0.97      0.96     20000\n",
      "\n",
      "    accuracy                           0.96    100000\n",
      "   macro avg       0.96      0.96      0.96    100000\n",
      "weighted avg       0.96      0.96      0.96    100000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T19:52:24.128983Z",
     "start_time": "2024-12-08T19:49:24.277784Z"
    }
   },
   "cell_type": "code",
   "source": "random_forest_model = train_random_forest(X, y)",
   "id": "ab80255e5eb52854",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      4018\n",
      "           1       0.97      0.89      0.93      4015\n",
      "           2       0.91      0.99      0.95      4002\n",
      "           3       0.93      0.94      0.94      3987\n",
      "           4       0.93      0.97      0.95      3978\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.94      0.94      0.94     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T02:44:46.725853Z",
     "start_time": "2024-12-08T20:00:08.147381Z"
    }
   },
   "cell_type": "code",
   "source": "svm_model = train_svm(X, y)",
   "id": "78cc2dfd1049f74a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM Evaluation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      4018\n",
      "           1       0.96      0.91      0.93      4015\n",
      "           2       0.91      0.98      0.95      4002\n",
      "           3       0.95      0.93      0.94      3987\n",
      "           4       0.94      0.97      0.95      3978\n",
      "\n",
      "    accuracy                           0.94     20000\n",
      "   macro avg       0.94      0.94      0.94     20000\n",
      "weighted avg       0.94      0.94      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#LSTM\n",
    "# Prepare data for LSTM\n",
    "def prepare_data_for_lstm(df, text_column='text', label_column='label'):\n",
    "    tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(df[text_column])\n",
    "    sequences = tokenizer.texts_to_sequences(df[text_column])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
    "    return padded_sequences, df[label_column].values, tokenizer\n",
    "\n",
    "\n",
    "X_lstm, y_lstm, tokenizer_lstm = prepare_data_for_lstm(df)"
   ],
   "id": "523c09bbb7254635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train/Test split\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)\n"
   ],
   "id": "612bbf550914ae26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Build LSTM model\n",
    "def build_lstm_model(vocab_size, embedding_dim, input_length):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=input_length),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ],
   "id": "27566aff4d9cd794"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lstm_model = build_lstm_model(vocab_size=20000, embedding_dim=100, input_length=100)\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, validation_split=0.2, epochs=5, batch_size=32)\n"
   ],
   "id": "b25c7c22424fb46a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate LSTM\n",
    "lstm_predictions = lstm_model.predict(X_test_lstm)\n",
    "lstm_pred_classes = np.argmax(lstm_predictions, axis=1)\n",
    "print(\"\\n--- LSTM Evaluation ---\")\n",
    "print(classification_report(y_test_lstm, lstm_pred_classes))\n"
   ],
   "id": "8592e70a0bb56b70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare data for BERT\n",
    "def prepare_data_for_bert(df, text_column='text', label_column='label'):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    inputs = tokenizer(list(df[text_column]), padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    labels = torch.tensor(df[label_column].values)\n",
    "    return inputs, labels"
   ],
   "id": "c2bee4896737ad86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bert_inputs, bert_labels = prepare_data_for_bert(df)\n",
   "id": "df38cece7c2de65e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train/Test split for BERT\n",
    "train_size = int(0.8 * len(bert_labels))\n",
    "train_inputs = {k: v[:train_size] for k, v in bert_inputs.items()}\n",
    "train_labels = bert_labels[:train_size]\n",
    "test_inputs = {k: v[train_size:] for k, v in bert_inputs.items()}\n",
    "test_labels = bert_labels[train_size:]\n"
   ],
   "id": "c30fd0f6537ed6a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fine-tune BERT model\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n"
   ],
   "id": "3d0ac3b0e7f6a09e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")"
   ],
   "id": "535bc77320132cb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=list(zip(train_inputs['input_ids'], train_labels)),\n",
    "    eval_dataset=list(zip(test_inputs['input_ids'], test_labels))\n",
    ")"
   ],
   "id": "3a5d062d41a3eed6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train()",
   "id": "b40b5d4559aaddc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluate BERT\n",
    "bert_outputs = bert_model(**test_inputs)\n",
    "bert_pred_classes = torch.argmax(bert_outputs.logits, axis=1)\n",
    "print(\"\\n--- BERT Evaluation ---\")\n",
    "print(classification_report(test_labels.numpy(), bert_pred_classes.numpy()))"
   ],
   "id": "53c5f6781920afa4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
