{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Emotion Analysis",
   "id": "acbc7d2403c10b3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import Libraries",
   "id": "affe3330009c94a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "import pytorch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ],
   "id": "da29198623cafa10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load and Explore Data",
   "id": "95518ec18d1eaba6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load the dataset from a file.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def explore_data(df, text_column='text'):\n",
    "    \"\"\"\n",
    "    Perform an extensive exploration of the dataset to check data cleanliness.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    - text_column: Name of the column containing text data\n",
    "\n",
    "    Returns:\n",
    "    - Summary of findings\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Basic Information ---\")\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Missing Values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicate Rows: {df.duplicated().sum()}\")\n",
    "\n",
    "    print(\"\\n--- Class Distribution ---\")\n",
    "    if 'label' in df.columns:\n",
    "        print(df['label'].value_counts())\n",
    "    else:\n",
    "        print(\"No 'label' column found!\")\n",
    "\n",
    "    print(\"\\n--- Text Analysis ---\")\n",
    "    # Check for empty or blank text\n",
    "    empty_texts = df[text_column].isnull().sum() + df[text_column].str.strip().eq('').sum()\n",
    "    print(f\"Empty or Blank Texts: {empty_texts}\")\n",
    "\n",
    "    # Check for punctuation\n",
    "    punctuations = df[text_column].apply(lambda x: len(re.findall(r'[^\\w\\s]', str(x))))\n",
    "    print(f\"Average Punctuation Count per Entry: {punctuations.mean():.2f}\")\n",
    "\n",
    "    # Check for emojis\n",
    "    emojis = df[text_column].apply(lambda x: len(emoji.emoji_list(str(x))))\n",
    "    print(f\"Average Emoji Count per Entry: {emojis.mean():.2f}\")\n",
    "\n",
    "    # Check for stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_word_counts = df[text_column].apply(lambda x: len([word for word in str(x).split() if word.lower() in stop_words]))\n",
    "    print(f\"Average Stop Words per Entry: {stop_word_counts.mean():.2f}\")\n",
    "\n",
    "    # Check for special characters (non-alphanumeric)\n",
    "    special_chars = df[text_column].apply(lambda x: len(re.findall(r'[^\\w\\s]', str(x))))\n",
    "    print(f\"Average Special Characters per Entry: {special_chars.mean():.2f}\")\n",
    "\n",
    "    print(\"\\n--- Recommendations ---\")\n",
    "    recommendations = []\n",
    "    if empty_texts > 0:\n",
    "        recommendations.append(f\"Remove or handle {empty_texts} empty or blank entries.\")\n",
    "    if df.duplicated().sum() > 0:\n",
    "        recommendations.append(\"Remove duplicate rows.\")\n",
    "    if emojis.mean() > 0:\n",
    "        recommendations.append(\"Consider handling emojis (e.g., replace with words or remove).\")\n",
    "    if punctuations.mean() > 0:\n",
    "        recommendations.append(\"Remove or handle punctuation marks appropriately.\")\n",
    "    if special_chars.mean() > 0:\n",
    "        recommendations.append(\"Clean special characters from text.\")\n",
    "\n",
    "    if recommendations:\n",
    "        print(\"\\n\".join(recommendations))\n",
    "    else:\n",
    "        print(\"The dataset appears clean!\")\n",
    "\n",
    "def drop_empty_rows(df):\n",
    "    \"\"\"Drop rows with empty text values.\"\"\"\n",
    "    return df.dropna(subset=['text']).reset_index(drop=True)"
   ],
   "id": "bb8f92b59e62f46f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Preprocess Text",
   "id": "339eedc44668e730"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"Remove emojis from text.\"\"\"\n",
    "    return emoji.replace_emoji(text, replace=\"\")\n",
    "\n",
    "def remove_punctuation_and_symbols(text):\n",
    "    \"\"\"Remove punctuation, numbers, and special characters.\"\"\"\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text.\"\"\"\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_punctuation_and_symbols(text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def apply_preprocessing(df):\n",
    "    \"\"\"Apply preprocessing to the text column.\"\"\"\n",
    "    df['text'] = df['text'].apply(preprocess_text)\n",
    "    return df\n"
   ],
   "id": "88bd508c16219733"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature Engineering",
   "id": "2371f0912fa9de6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_features(corpus):\n",
    "    \"\"\"Convert text into numerical representations.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return features, vectorizer"
   ],
   "id": "3ae90cd91878a822"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model Training",
   "id": "9ed49450c558445c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Logistic Regression",
   "id": "a8cdcfa189750968"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_logistic_regression(X, y):\n",
    "    \"\"\"Train and evaluate a Logistic Regression model.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- Logistic Regression Evaluation ---\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model"
   ],
   "id": "e63d7bfe4eacfe85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Random Forest",
   "id": "8dfbb560f6a2a251"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_random_forest(X, y):\n",
    "    \"\"\"Train and evaluate a Random Forest Classifier.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- Random Forest Evaluation ---\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model"
   ],
   "id": "1d2a6f4e4cd8223e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Support Vector Machine",
   "id": "7153c9dd7aacc9bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_svm(X, y):\n",
    "    \"\"\"Train and evaluate a Support Vector Machine (SVM).\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = SVC(probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\n--- SVM Evaluation ---\")\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model\n"
   ],
   "id": "280ea5462c80f349"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Evaluate Model",
   "id": "3164d5a10ba74dd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Evaluation Function\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the performance of a trained model.\"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))"
   ],
   "id": "52e290795d534f01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Predict",
   "id": "f39275ac3d8f700a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_emotion(model, text, vectorizer):\n",
    "    \"\"\"Predict the emotion of a single input text.\"\"\"\n",
    "    processed_text = preprocess_text(text)\n",
    "    features = vectorizer.transform([processed_text])\n",
    "    return model.predict(features)\n"
   ],
   "id": "c8a1e03edcde6613"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
